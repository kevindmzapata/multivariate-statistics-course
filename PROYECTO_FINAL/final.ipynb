{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAREA NO. 3 - ESTADÍSTICA MULTIVARIADA: REGRESIÓN MULTIVARIADA\n",
    "\n",
    "## 1. Contexto de la base de datos\n",
    "Este conjutno de datos contiene seis meses de datos de consumo eléctrico de un hogar, recogidos entre enero y junio de 2007. Los datos incluyen información sobre potencia activa global, potencia reactiva global, tensión, intensidad global, submedición 1 (cocina), submedición 2 (lavadero) y submedición 3 (calentador de agua eléctrico y aire acondicionado). Con 260.640 mediciones en total, el objetivo es predecir o estimar el consumo eléctrico de los hogares.\n",
    "\n",
    "| Nombre de la columna | Descripción |\n",
    "| --- | --- |\n",
    "| Fecha | La fecha de la observación. (Fecha) |\n",
    "| Hora | La hora de la observación. (Hora) |\n",
    "| Potencia_activa_global | La potencia activa total consumida por el hogar (kilovatios). (Numérico) |\n",
    "| Potencia_reactiva_global | La potencia reactiva total consumida por el hogar (kilovatios). (Numérico) |\n",
    "| Voltaje | El voltaje al cual se entrega la electricidad al hogar (voltios). (Numérico) |\n",
    "| Intensidad_global | La intensidad de corriente promedio entregada al hogar (amperios). (Numérico) |\n",
    "| Sub_medición_1 | La potencia activa consumida por la cocina (kilovatios). (Numérico) |\n",
    "| Sub_medición_2 | La potencia activa consumida por la lavandería (kilovatios). (Numérico) |\n",
    "| Sub_medición_3 | La potencia activa consumida por el calentador de agua eléctrico y el aire acondicionado (kilovatios). (Numérico) |\n",
    "\n",
    "La variable respuesta para el modelo de regresión múltiple es la potencia aparente global en la red. A priori, esta variable no está incluida dentro del conjunto de datos, por lo que es necesario obtenerla a parir de la potencia reactiva y activa global que si están disponibles en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis descriptivo de los datos\n",
    "\n",
    "### 1.1. Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('database.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores '?' con NaN para identificar valores faltantes de manera uniforme\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Convertir columnas numéricas de tipo object a float donde sea necesario\n",
    "numeric_columns = [\n",
    "    'Global_active_power',\n",
    "    'Global_reactive_power',\n",
    "    'Voltage',\n",
    "    'Global_intensity',\n",
    "    'Sub_metering_1',\n",
    "    'Sub_metering_2',\n",
    "]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# Verificar los cambios y la cantidad de valores faltantes\n",
    "missing_data_summary = data.isnull().sum()\n",
    "\n",
    "missing_data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas Date y Time en un índice temporal para realizar la interpolación correctamente\n",
    "data['Datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])\n",
    "data.set_index('Datetime', inplace=True)\n",
    "\n",
    "# Eliminar las columnas originales de fecha y hora para evitar redundancia\n",
    "data.drop(columns=['Date', 'Time'], inplace=True)\n",
    "\n",
    "# Aplicar interpolación lineal en todas las columnas numéricas\n",
    "data_interpolated = data.interpolate(method='time')\n",
    "\n",
    "# Verificar si quedan valores faltantes\n",
    "remaining_missing = data_interpolated.isnull().sum()\n",
    "\n",
    "remaining_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_interpolated['Global_apparent_power'] = np.sqrt(data_interpolated['Global_active_power']**2 + data_interpolated['Global_reactive_power']**2)\n",
    "data_interpolated.drop(columns=['Global_active_power', 'Global_reactive_power'], inplace=True)\n",
    "data_interpolated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Análisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis descriptivo de las columnas numéricas\n",
    "descriptive_analysis = data_interpolated.describe()\n",
    "descriptive_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Análisis exploratorio visual: Crear gráficas clave\n",
    "\n",
    "# 1. Distribución de la Potencia Aparente Global\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data_interpolated['Global_apparent_power'], bins=50, edgecolor='k')\n",
    "plt.title('Distribución de la Potencia Aparente Global')\n",
    "plt.xlabel('Potencia Aparente Global (kW)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "# 2. Tendencia de la Tensión (Voltage) a lo largo del tiempo\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(data_interpolated.index, data_interpolated['Voltage'], alpha=0.6)\n",
    "plt.title('Tendencia de la Tensión a lo largo del Tiempo')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Tensión (V)')\n",
    "plt.show()\n",
    "\n",
    "# 3. Relación entre Potencia Aparente Global y Corriente Global\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    data_interpolated['Global_apparent_power'],\n",
    "    data_interpolated['Global_intensity'],\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.title('Relación entre Potencia Aparente Global y Corriente Global')\n",
    "plt.xlabel('Potencia Aparente Global (kW)')\n",
    "plt.ylabel('Corriente Global (A)')\n",
    "plt.show()\n",
    "\n",
    "# 4. Boxplot de Submeterings\n",
    "plt.figure(figsize=(10, 6))\n",
    "data_interpolated[['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']].boxplot()\n",
    "plt.title('Distribución de Submeterings')\n",
    "plt.ylabel('Consumo de Energía (Wh)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_interpolated.drop(columns=['Global_apparent_power'])\n",
    "y = data_interpolated['Global_apparent_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Análisis de correlación de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# Graficar un mapa de calor para visualizar las correlaciones\n",
    "plt.figure()\n",
    "plt.matshow(correlation_matrix, cmap='coolwarm', fignum=1)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(correlation_matrix.shape[1]), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(range(correlation_matrix.shape[0]), correlation_matrix.columns)\n",
    "plt.title('Matriz de Correlación entre Variables', pad=20)\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlaciones Bajas:\n",
    "- Voltage tiene una correlación negativa moderada con Global_apparent_power y Global_intensity.\n",
    "\n",
    "Correlación entre Submeterings:\n",
    "- Las submediciones (Sub_metering_1, Sub_metering_2, y Sub_metering_3) presentan correlaciones bajas entre ellas, lo que sugiere que capturan consumos de energía en diferentes fuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Reducción de la dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selección de las columnas numéricas para aplicar PCA\n",
    "numeric_data = X.drop(columns=['index'])\n",
    "\n",
    "# Escalar los datos para PCA\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_data)\n",
    "\n",
    "# Aplicar PCA para identificar el número óptimo de componentes\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "\n",
    "# Calcular la proporción acumulada de varianza explicada\n",
    "explained_variance_ratio = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Graficar la proporción acumulada de varianza explicada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o')\n",
    "plt.title('Proporción Acumulada de Varianza Explicada (PCA)')\n",
    "plt.xlabel('Número de Componentes Principales')\n",
    "plt.ylabel('Proporción de Varianza Explicada')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Elegir el número óptimo de componentes que expliquen al menos el 70% de la varianza\n",
    "optimal_components = (explained_variance_ratio >= 0.7).argmax() + 1\n",
    "\n",
    "# Aplicar PCA con el número óptimo de componentes\n",
    "pca = PCA(n_components=optimal_components)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Convertir los datos reducidos a un DataFrame para análisis posterior\n",
    "pca_columns = [f'PC{i+1}' for i in range(optimal_components)]\n",
    "reduced_df = pd.DataFrame(reduced_data, columns=pca_columns, index=data_interpolated.index)\n",
    "\n",
    "reduced_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un biplot para visualizar cómo las variables originales contribuyen a las componentes principales\n",
    "# Para esto, se utiliza la proyección de las variables originales en el espacio de los componentes principales.\n",
    "\n",
    "# Obtener los pesos (loadings) de las variables originales en las primeras dos componentes principales\n",
    "loadings = pca.components_.T[:, :2]\n",
    "\n",
    "# Crear el biplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Gráfico de las muestras en el espacio de las primeras dos componentes principales\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], alpha=0.3, label='Datos (Proyección)')\n",
    "\n",
    "# Añadir las contribuciones de las variables originales\n",
    "for i, column in enumerate(numeric_data.columns):\n",
    "    plt.arrow(0, 0, loadings[i, 0] * 5, loadings[i, 1] * 5, \n",
    "              color='r', alpha=0.5, head_width=0.1)\n",
    "    plt.text(loadings[i, 0] * 5.5, loadings[i, 1] * 5.5, column, \n",
    "             color='r', ha='center', va='center')\n",
    "\n",
    "plt.title('Biplot: Componentes Principales y Variables Originales')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.axhline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axvline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El biplot muestra la proyección de los datos en las dos primeras componentes principales y las contribuciones de las variables originales a estas componentes:\n",
    "\n",
    "- Los vectores rojos indican qué tanto y en qué dirección cada variable contribuye a las componentes principales.\n",
    "- Las variables con vectores más largos tienen un mayor peso en las componentes.\n",
    "- La proximidad entre vectores de variables sugiere correlación entre estas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs, fig = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Gráfico de la primera componente principal\n",
    "sns.histplot(reduced_df['PC1'], bins=50, kde=True, color='b', ax=fig[0])\n",
    "fig[0].set_title('Distribución de PC1')\n",
    "fig[0].set_xlabel('PC1')\n",
    "fig[0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Gráfico de la segunda componente principal\n",
    "sns.histplot(reduced_df['PC2'], bins=50, kde=True, color='g', ax=fig[1])\n",
    "fig[1].set_title('Distribución de PC2')\n",
    "fig[1].set_xlabel('PC2')\n",
    "fig[1].set_ylabel('Frecuencia')\n",
    "\n",
    "# Gráfico de la tercera componente principal\n",
    "sns.histplot(reduced_df['PC3'], bins=50, kde=True, color='r', ax=fig[2])\n",
    "fig[2].set_title('Distribución de PC3')\n",
    "fig[2].set_xlabel('PC3')\n",
    "fig[2].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs, fig = plt.subplots(3, 1, figsize=(15, 10))\n",
    "\n",
    "# Gráfico de la primera componente principal\n",
    "sns.lineplot(data=reduced_df['PC1'], ax=fig[0])\n",
    "fig[0].set_title('Tendencia de PC1')\n",
    "fig[0].set_xlabel('Tiempo')\n",
    "fig[0].set_ylabel('PC1')\n",
    "\n",
    "# Gráfico de la segunda componente principal\n",
    "sns.lineplot(data=reduced_df['PC2'], ax=fig[1])\n",
    "fig[1].set_title('Tendencia de PC2')\n",
    "fig[1].set_xlabel('Tiempo')\n",
    "fig[1].set_ylabel('PC2')\n",
    "\n",
    "# Gráfico de la tercera componente principal\n",
    "sns.lineplot(data=reduced_df['PC3'], ax=fig[2])\n",
    "fig[2].set_title('Tendencia de PC3')\n",
    "fig[2].set_xlabel('Tiempo')\n",
    "fig[2].set_ylabel('PC3')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis de series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Verificación de la estacionaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series, column_name):\n",
    "    result = adfuller(series)\n",
    "    p_value = result[1]\n",
    "    print(f\"Prueba de Dickey-Fuller para {column_name}:\")\n",
    "    print(f\"  Estadístico ADF: {result[0]:.4f}\")\n",
    "    print(f\"  Valor p: {p_value:.4f}\")\n",
    "    print(f\"  Valores Críticos: {result[4]}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"  La serie '{column_name}' es estacionaria (p < 0.05).\\n\")\n",
    "    else:\n",
    "        print(f\"  La serie '{column_name}' no es estacionaria (p >= 0.05).\\n\")\n",
    "        \n",
    "for column in reduced_df.columns:\n",
    "    check_stationarity(reduced_df[column], column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# Usaremos un 80% para entrenamiento y 20% para prueba\n",
    "train_size = int(len(reduced_df) * 0.8)\n",
    "\n",
    "train_data = reduced_df.iloc[:train_size]\n",
    "test_data = reduced_df.iloc[train_size:]\n",
    "\n",
    "# Mostrar un resumen de las divisiones\n",
    "train_summary = {\n",
    "    \"Train Start\": train_data.index[0],\n",
    "    \"Train End\": train_data.index[-1],\n",
    "    \"Test Start\": test_data.index[0],\n",
    "    \"Test End\": test_data.index[-1],\n",
    "    \"Train Size\": len(train_data),\n",
    "    \"Test Size\": len(test_data),\n",
    "}\n",
    "\n",
    "train_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que hay un problema persistente con los cálculos en este entorno. Permítanme resumir los pasos típicos para dividir el conjunto de datos:\n",
    "\n",
    "Dividir en entrenamiento y prueba:\n",
    "- Utilizar el 80% de los datos para el entrenamiento y el 20% para las pruebas. Esto es habitual en los modelos de series temporales para \n",
    "evaluar el rendimiento predictivo.\n",
    "\n",
    "Límite entrenamiento-prueba:\n",
    "- La división respeta el orden temporal (sin barajar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Generación del modelo ARIMA y ajuste de los parametros (d, p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias para mantener la salida limpia\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Intentar graficar ACF y PACF para las tres componentes principales en un solo gráfico\n",
    "\n",
    "lags = 40  # Número de lags para ACF y PACF\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "for i, component in enumerate(reduced_df.columns):\n",
    "    # Graficar ACF\n",
    "    plot_acf(reduced_df[component], lags=lags, ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'{component} - ACF')\n",
    "    \n",
    "    # Graficar PACF\n",
    "    plot_pacf(reduced_df[component], lags=lags, ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'{component} - PACF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pmdarima import auto_arima\n",
    "\n",
    "# # Determine optimal ARIMA parameters for each component\n",
    "# for component in reduced_df.columns:\n",
    "#     stepwise_fit = auto_arima(reduced_df[component], seasonal=False, trace=True)\n",
    "#     print(f\"Optimal parameters for {component}: {stepwise_fit.order}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
